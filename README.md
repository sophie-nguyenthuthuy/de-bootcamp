
# de-bootcamp
# DATA ENGINEERING BOOTCAMP ‚Äì H∆Ø·ªöNG D·∫™N SETUP M√îI TR∆Ø·ªúNG LAB
# üìò DATA ENGINEERING BOOTCAMP ‚Äî STUDENT SETUP GUIDE

6‚Äì9 Week Program: Big Data, Lakehouse, Spark, Kafka, Airflow, Trino, Data Governance

Repo n√†y ch·ª©a to√†n b·ªô h·∫° t·∫ßng c·∫ßn thi·∫øt ƒë·ªÉ h·ªçc vi√™n t·ª± ch·∫°y c√°c lab trong kh√≥a h·ªçc.

---

## 1. Y√äU C·∫¶U M√ÅY T√çNH

| Component | Recommendation |
|----------|----------------|
| CPU | ‚â• 4 vCPU |
| RAM | ‚â• 16 GB |
| Disk | ‚â• 50 GB |
| OS | macOS / Windows WSL2 / Linux |
| Tools | Docker Desktop, Git, Python 3.10 |

---

## 2. CLONE REPOSITORY

```bash
git clone https://github.com/your-org/de-bootcamp.git
cd de-bootcamp
```

---

## 3. KH·ªûI CH·∫†Y DOCKER COMPOSE

**Compose file:** M·∫∑c ƒë·ªãnh d√πng **`docker-compose.yml`** (Postgres, MinIO, Hive Metastore, Trino; m·ªôt network `de-bootcamp_default`).  
**Tu·ª≥ ch·ªçn:** `docker-compose.fixed.yml` v√† `docker-compose.clean.yml` l√† b·∫£n d√πng profiles v√† network `de-net`; ch·ªâ d√πng khi c·∫ßn ch·∫°y t·ª´ng nh√≥m d·ªãch v·ª• (core / lakehouse / spark / streaming / airflow / bi) ri√™ng.

### Ch·∫°y Core (Postgres + MinIO):
```bash
docker compose --profile core up -d
```

### Ch·∫°y Lakehouse (Trino + Hive + MinIO):
```bash
docker compose --profile lakehouse --profile spark up -d
```

### Ch·∫°y Kafka + Debezium (CDC):
```bash
docker compose --profile streaming up -d
```

### Ch·∫°y Airflow:
```bash
docker compose --profile airflow up -d
```

### Ch·∫°y to√†n b·ªô stack (n·∫∑ng):
```bash
docker compose up -d
```

### D·ª´ng t·∫•t c·∫£:
```bash
docker compose down
```

---

## 4. KI·ªÇM TRA D·ªäCH V·ª§

### Postgres
```bash
psql postgresql://de_user:de_pass@localhost:5432/de_db
```

### MinIO Console
```
http://localhost:9001
User: minioadmin
Pass: minioadmin
```

### Trino UI
```
User: admin
http://localhost:8080
```

### Airflow UI
```
http://localhost:8088
User: admin
Pass: admin
```

### Metabase
```
http://localhost:3000
```

---

## 5. KH·ªûI T·∫†O D·ªÆ LI·ªÜU OLTP

### Ch·∫°y file t·∫°o schema:
```bash
psql postgresql://de_user:de_pass@localhost:5432/de_db -f sql/01_create_oltp_schema.sql
```

### Seed d·ªØ li·ªáu m·∫´u:
```bash
psql postgresql://de_user:de_pass@localhost:5432/de_db -f sql/02_seed_sample_data.sql
```

---

## 6. TEST TRINO + MINIO + LAKEHOUSE

M·ªü Trino CLI ho·∫∑c web UI ‚Üí ch·∫°y:

```sql
SHOW CATALOGS;
SHOW SCHEMAS FROM hive;

CREATE SCHEMA hive.lakehouse 
WITH (location='s3a://lakehouse/');
```

---

## 7. CH·∫†Y DAG AIRFLOW

### Example 1 ‚Äî Postgres ‚Üí MinIO (Bronze)

Trong Airflow UI, b·∫≠t DAG:

```
postgres_to_minio_etl
```

Sau ƒë√≥ ki·ªÉm tra file xu·∫•t hi·ªán trong MinIO:

- bucket: **lakehouse**
- path: **bronze/orders/orders_extract.csv**

---

## 8. CH·∫†Y SPARK JOB (Bronze ‚Üí Silver ‚Üí Gold)

Airflow DAG:

```
spark_bronze_to_silver_gold
```

Job th·ª±c hi·ªán:

- ƒê·ªçc CSV t·ª´ MinIO  
- L√†m s·∫°ch d·ªØ li·ªáu  
- Ghi Silver (Parquet) ph√¢n v√πng theo ng√†y  
- T√≠nh Gold metrics (daily revenue, total orders‚Ä¶)  

---

## 9. C·∫§U TR√öC D·ªÆ LI·ªÜU LAKEHOUSE

```
lakehouse/
‚îú‚îÄ raw/
‚îú‚îÄ bronze/
‚îÇ   ‚îî‚îÄ orders/
‚îú‚îÄ silver/
‚îÇ   ‚îî‚îÄ orders_clean/
‚îî‚îÄ gold/
    ‚îî‚îÄ orders_daily_metrics/
```

---

## 10. KAFKA + DEBEZIUM (CDC)

Test Debezium:

### Insert v√†o PostgreSQL:
```sql
INSERT INTO app.orders (customer_id, order_date, status)
VALUES (1, CURRENT_DATE, 'created');
```

### Check topic Kafka:
```
connect-debezium.app.orders
```

D·ªØ li·ªáu CDC s·∫Ω ƒë∆∞·ª£c stream sang MinIO ho·∫∑c Spark Streaming.

---

## 11. S·ª∞ C·ªê TH∆Ø·ªúNG G·∫∂P

### Docker b·ªã treo ‚Üí restart stack:
```bash
docker compose down -v
docker system prune -af
docker compose up -d
```

### Airflow kh√¥ng nh·∫≠n DAG?
```bash
docker exec -it de_airflow ls /opt/airflow/dags-local
```

### Trino kh√¥ng th·∫•y catalog hive?
```bash
docker compose restart trino
```

---

## 12. LI√äN H·ªÜ / H·ªñ TR·ª¢

N·∫øu c·∫ßn h·ªó tr·ª£ trong l√∫c h·ªçc, h·ªçc vi√™n c√≥ th·ªÉ m·ªü issue trong repo ho·∫∑c h·ªèi tr·ª±c ti·∫øp trong l·ªõp.

---

# 13. PH·ª§ L·ª§C ‚Äì C√ÇU L·ªÜNH M·∫™U KI·ªÇM TRA T·ª™NG LAB

## 13.1 SQL Lab ‚Äì Ki·ªÉm tra schema & d·ªØ li·ªáu OLTP

Sau khi ch·∫°y:

```bash
psql postgresql://de_user:de_pass@localhost:5432/de_db -f sql/01_create_oltp_schema.sql
psql postgresql://de_user:de_pass@localhost:5432/de_db -f sql/02_seed_sample_data.sql
```
## 13.2 Lakehouse / Trino / MinIO ‚Äì Ki·ªÉm tra ho·∫°t ƒë·ªông

Sau khi b·∫≠t core + lakehouse:

```bash
docker compose --profile core --profile lakehouse up -d
```

M·ªü Trino UI t·∫°i:

```
http://localhost:8080
```

Ch·∫°y c√°c l·ªánh ki·ªÉm tra:

```sql
SHOW CATALOGS;

SHOW SCHEMAS FROM hive;

CREATE SCHEMA IF NOT EXISTS hive.lakehouse
WITH (location='s3a://lakehouse/');

SHOW TABLES FROM hive.lakehouse;
```

N·∫øu b·∫°n ƒë√£ load file CSV v√†o MinIO (bronze), t·∫°o b·∫£ng external ƒë·ªÉ ƒë·ªçc:

```sql
CREATE TABLE hive.lakehouse.orders_bronze (
    order_id        integer,
    customer_id     integer,
    order_date      date,
    total_amount    double
)
WITH (
    external_location='s3a://lakehouse/bronze/orders/',
    format='CSV',
    skip_header_line_count = 1
);

SELECT * FROM hive.lakehouse.orders_bronze LIMIT 10;
```

---

## 13.3 Spark Lab ‚Äì Ki·ªÉm tra job Bronze ‚Üí Silver ‚Üí Gold

B·∫≠t lakehouse + spark:

```bash
docker compose --profile lakehouse --profile spark up -d
```

Ch·∫°y Spark job tr·ª±c ti·∫øp qua spark-submit:

```bash
docker exec -it de_spark_master \
  spark-submit \
    --master spark://spark-master:7077 \
    /opt/airflow/spark_jobs/bronze_to_silver_gold.py \
    s3a://lakehouse/bronze/orders/orders_extract.csv \
    s3a://lakehouse/silver/orders_clean/ \
    s3a://lakehouse/gold/orders_daily_metrics/ \
    http://minio:9000 \
    minioadmin \
    minioadmin
```

Sau khi job ch·∫°y xong, ki·ªÉm tra b·∫±ng Trino:

```sql
SELECT * FROM hive.lakehouse.orders_silver LIMIT 10;

SELECT * FROM hive.lakehouse.orders_daily_metrics LIMIT 10;
```

---

## 13.4 Kafka ‚Äì Ki·ªÉm tra Kafka Broker & Topic

B·∫≠t Kafka + Zookeeper:

```bash
docker compose --profile streaming up -d
```

Truy c·∫≠p container Kafka:

```bash
docker exec -it de_kafka bash
```

T·∫°o topic:

```bash
kafka-topics --create \
  --bootstrap-server kafka:9092 \
  --replication-factor 1 \
  --partitions 1 \
  --topic test-topic
```

List topic:

```bash
kafka-topics --list --bootstrap-server kafka:9092
```

Producer test:

```bash
kafka-console-producer --broker-list kafka:9092 --topic test-topic
>hello
>this is a test
```

Consumer:

```bash
kafka-console-consumer --bootstrap-server kafka:9092 \
  --topic test-topic \
  --from-beginning
```

---

## 13.5 CDC (Debezium) ‚Äì Ki·ªÉm tra Connector

Trong terminal:

```bash
curl http://localhost:8083/connectors
```

Ki·ªÉm tra tr·∫°ng th√°i connector (v√≠ d·ª•: debezium-postgres-orders):

```bash
curl http://localhost:8083/connectors/debezium-postgres-orders/status
```

Insert th·ª≠ d·ªØ li·ªáu v√†o Postgres:

```sql
INSERT INTO app.orders(customer_id, order_date, status)
VALUES (1, CURRENT_DATE, 'created');
```

Consumer CDC topic (t√πy connector config):

```bash
kafka-console-consumer \
  --bootstrap-server kafka:9092 \
  --topic dbserver1.app.orders \
  --from-beginning
```

---

## 13.6 Airflow ‚Äì Ki·ªÉm tra DAG & Scheduler

List DAGs:

```bash
docker exec -it de_airflow airflow dags list
```

Show DAG graph:

```bash
docker exec -it de_airflow airflow dags show postgres_to_minio_etl
```

Trigger DAG:

```bash
docker exec -it de_airflow airflow dags trigger postgres_to_minio_etl
```

Xem l·ªãch s·ª≠ ch·∫°y:

```bash
docker exec -it de_airflow airflow dags list-runs postgres_to_minio_etl
```

Ki·ªÉm tra logs:

```bash
docker exec -it de_airflow airflow tasks logs postgres_to_minio_etl extract_from_postgres
```

---

## 13.7 Metabase ‚Äì Ki·ªÉm tra k·∫øt n·ªëi Postgres

Truy c·∫≠p v√†o:

```
http://localhost:3000
```

Th√™m database m·ªõi:

- **Type:** Postgres  
- **Host:** postgres  
- **Port:** 5432  
- **DB name:** de_db  
- **User:** de_user  
- **Password:** de_pass  

T·∫°o c√¢u h·ªèi (Question):

```sql
SELECT order_date, total_amount
FROM app.orders
ORDER BY order_date DESC;
```

N·∫øu query ch·∫°y OK ‚Üí k·∫øt n·ªëi th√†nh c√¥ng.

```

